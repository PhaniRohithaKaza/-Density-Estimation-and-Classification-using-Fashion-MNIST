{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZAdpXh7M_d_"
      },
      "source": [
        "#Importing the Libraries\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "from scipy.io import loadmat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIG4Spa3OKD9"
      },
      "source": [
        "#Loading the dataset\n",
        "fashion_data = loadmat('fashion_mnist.mat')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04-AEBgCPLlP"
      },
      "source": [
        "#Partitioning the dataset into Train Features, Train Labels, Test Features &Test Labels\n",
        "fashion_train_X=fashion_data['trX']\n",
        "fashion_train_y=fashion_data['trY']\n",
        "fashion_test_X=fashion_data['tsX']\n",
        "fashion_test_y=fashion_data['tsY']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riU2BhvnRZjM"
      },
      "source": [
        "#Caluclating the features by taking average of all the pixel values as X1 and standard deviation of all pixel values as X2 in train data\n",
        "#Train Data\n",
        "X1=np.mean(fashion_train_X, axis=1, dtype=np.float64)\n",
        "X2=np.std(fashion_train_X, axis=1, dtype=np.float64)\n",
        "#Caluclating the features by taking average of all the pixel values as x1 and standard deviation of all pixel values as x2 in test data\n",
        "#Train Data\n",
        "x1=np.mean(fashion_test_X, axis=1, dtype=np.float64)\n",
        "x2=np.std(fashion_test_X, axis=1, dtype=np.float64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TepI15FWY10v"
      },
      "source": [
        "#Creating Data Frame with the obtained features as Feature1 & Feature2 for train and test data\n",
        "train_data=pd.DataFrame(X1, columns=['Feature1'])\n",
        "train_data['Feature2']=X2\n",
        "test_data=pd.DataFrame(x1, columns=['Feature1'])\n",
        "test_data['Feature2']=x2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixtNSybNdM1f"
      },
      "source": [
        "train_data['class']=np.transpose(fashion_train_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgPNiJVdCVb6"
      },
      "source": [
        "#Estimating Parameters-Mean\n",
        "mean=dict()\n",
        "mean[0]=train_data[train_data['class']==0].drop(columns=['class']).mean()\n",
        "mean[1]=train_data[train_data['class']==1].drop(columns=['class']).mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlRzffvdCVYe",
        "outputId": "aa66789c-4436-4ae8-a0ee-15e774e85d84"
      },
      "source": [
        "#Printing estimated mean values\n",
        "mean"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: Feature1    0.325608\n",
              " Feature2    0.320036\n",
              " dtype: float64, 1: Feature1    0.222905\n",
              " Feature2    0.333942\n",
              " dtype: float64}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iFMm5VYCVUE",
        "outputId": "82efa7fb-0007-4907-dc6c-ac71eb62bfbe"
      },
      "source": [
        "#Estimating Parameters-Covariance Matrix\n",
        "covariance_matrix=dict()\n",
        "data=train_data[train_data['class']==0].drop(columns=['class'])\n",
        "data_1=data.sub(data.mean())\n",
        "datat_1=data_1.transpose()\n",
        "data2=train_data[train_data['class']==1].drop(columns=['class'])\n",
        "data_2=data2.sub(data2.mean())\n",
        "datat_2=data_2.transpose()\n",
        "covariance_matrix[0]=datat_1.dot(data_1).div(data.shape[0]-1)\n",
        "covariance_matrix[1]=datat_2.dot(data_2).div(data.shape[0]-1)\n",
        "covariance_matrix"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0:           Feature1  Feature2\n",
              " Feature1  0.012856  0.008979\n",
              " Feature2  0.008979  0.007742, 1:           Feature1  Feature2\n",
              " Feature1  0.003244  0.002530\n",
              " Feature2  0.002530  0.003253}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfJI1EtWCVRe"
      },
      "source": [
        "#Estimating Parameters-Standard Deviation\n",
        "import math\n",
        "standard_deviation=dict()\n",
        "standard_deviation[0]=pd.Series([math.sqrt(covariance_matrix[0]['Feature1']['Feature1']), math.sqrt(covariance_matrix[0]['Feature2']['Feature2'])], index=['Feature1', 'Feature2'])\n",
        "standard_deviation[1]=pd.Series([math.sqrt(covariance_matrix[1]['Feature1']['Feature1']), math.sqrt(covariance_matrix[1]['Feature2']['Feature2'])], index=['Feature1', 'Feature2'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ui7-qTe-CVOs",
        "outputId": "b19fd07e-edb7-4bdc-c151-7a3d8550f339"
      },
      "source": [
        "#Printing estimated standard deviation values\n",
        "standard_deviation"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: Feature1    0.113384\n",
              " Feature2    0.087990\n",
              " dtype: float64, 1: Feature1    0.056956\n",
              " Feature2    0.057037\n",
              " dtype: float64}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvvsDqkgCVMQ"
      },
      "source": [
        "#Naive Bayes Classifier\n",
        "\n",
        "#To compute Normal Distribution\n",
        "def gaussian_distribution(x,mean,sd):\n",
        "  exponential=math.exp(-(x-mean)**2/(2*sd**2))\n",
        "  a=math.sqrt(2*math.pi)*sd\n",
        "  return exponential/a\n",
        "\n",
        "#Caluclating Prior Probability\n",
        "def prior_probability(y_labels):\n",
        "  prior_of_classes=dict()\n",
        "  for i in y_labels['class'].value_counts().index:\n",
        "    prior_of_classes[int(i)]=y_labels['class'].value_counts().loc[i]/y_labels.shape[0]\n",
        "  return prior_of_classes\n",
        "\n",
        "#Caluclating Posterior Probability\n",
        "def posterior_probability(data_d):\n",
        "  probability=[(gaussian_distribution(data_d[i],mean[0][i],standard_deviation[0][i]), gaussian_distribution(data_d[i],mean[1][i],standard_deviation[1][i])) for i in data_d.index]\n",
        "  return (probability[0][0]*probability[1][0]*prior_of_train[0],probability[0][1]*probability[1][1]*prior_of_train[1])\n",
        "\n",
        "#Naive Bayes Classifier\n",
        "def naive_bayes(test_samples):\n",
        "  X=test_samples.apply(posterior_probability,axis=1, result_type='expand')\n",
        "  X['predictions']=X.idxmax(axis=1)\n",
        "  return X\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81Gl3MnUCVKO"
      },
      "source": [
        "#Caluclating Accuracy\n",
        "def accuracy(actual_class,predicted_class):\n",
        "  error=actual_class[0].sub(predicted_class['predictions']).abs().sum()\n",
        "  return (1-(error/float(actual_class.shape[0])))*100\n",
        "\n",
        "#Accuracy for each class\n",
        "def class_acc(datac):\n",
        "  d0=datac[datac['actual']==0]\n",
        "  d1=datac[datac['actual']==1]\n",
        "  acc0=(d0['actual'].sub(d0['Predict'])).abs().sum()\n",
        "  acc00=(1-(acc0/d0.shape[0]))*100\n",
        "  acc1=(d1['actual'].sub(d1['Predict'])).abs().sum()\n",
        "  acc11=(1-(acc1/d1.shape[0]))*100\n",
        "  return (acc00,acc11)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIFcEIm9CVHn",
        "outputId": "49b5d4a0-2b62-4f76-b595-68b2b6802137"
      },
      "source": [
        "#Naive Bayes Classifier \n",
        "prior_of_train=dict()\n",
        "global prior_of_train\n",
        "prior_of_train=prior_probability(train_data)\n",
        "predict=naive_bayes(test_data)\n",
        "acc=accuracy(pd.DataFrame(fashion_test_y.transpose()),pd.DataFrame(predict))\n",
        "#Printing the total accuracy of the built Naive Bayes Model\n",
        "print(\"Accuracy of the Naive Bayes:\"+str(acc)+\"%\")\n",
        "c2=pd.DataFrame()\n",
        "c2['Predict'] = predict['predictions']\n",
        "c2['actual']=fashion_test_y[0].transpose()\n",
        "res1=class_acc(c2)\n",
        "#Printing the accuracy for each class\n",
        "print(\"Accuracy of the Naive Bayes for class 0:\"+str(res1[0])+\"%\")\n",
        "print(\"Accuracy of the Naive Bayes for class 1:\"+str(res1[1])+\"%\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the Naive Bayes:83.15%\n",
            "Accuracy of the Naive Bayes for class 0:78.4%\n",
            "Accuracy of the Naive Bayes for class 1:87.9%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZOdiz5gCVFC"
      },
      "source": [
        "#Logistic Regression\n",
        "\n",
        "#Computing Sigmoid Function\n",
        "def sigmoid(weight,x):\n",
        "  w=x.dot(weight.transpose())\n",
        "  b=w.apply(sig)\n",
        "  return b\n",
        "\n",
        "def sig(x):\n",
        "  return 1/(1+math.exp(-x))\n",
        "\n",
        "#Caluclating Gradient Ascent for the Logistic Regression\n",
        "def gradient(w, y, z, x, learning):\n",
        "  y2=y-z\n",
        "  for i in x.columns:\n",
        "    w[i]+=learning*(y2.mul(x[i])).sum()\n",
        "  return w\n",
        "\n",
        "#Logistic Regression Model\n",
        "def logistic_regression(train_features, train_class, test, learning, epoch):\n",
        "  weights=pd.Series(np.random.randn(train_features.shape[1]+1), index=['1', 'Feature1', 'Feature2'])\n",
        "  train_double=train_features.copy()\n",
        "  train_double.insert(0,'1',1)\n",
        "  for i in range(epoch):\n",
        "    z=sigmoid(weights,train_double)\n",
        "    weights=gradient(weights,train_class, z, train_double,learning)\n",
        "  test_double=test.copy()\n",
        "  test_double.insert(0,'1',1)\n",
        "  return predicts(weights,test_double)\n",
        "\n",
        "#Predictions of test data\n",
        "def predicts(weights,test):\n",
        "  z=sigmoid(weights,test)\n",
        "  return z.apply(round)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lN72mF8YCVCo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "389e2708-f3b9-4f6e-8b4b-475e5f7a904f"
      },
      "source": [
        "#Caluclating the accuracy for the Logistic Regression test data\n",
        "pred=logistic_regression(train_data.drop(columns=['class']), train_data['class'], test_data,0.02,300)\n",
        "acc1=accuracy(pd.DataFrame(fashion_test_y.transpose()),pd.DataFrame(pred,columns=['predictions']))\n",
        "print(\"Accuracy of the Logistic Regression:\"+str(acc1)+\"%\")\n",
        "c1=pd.DataFrame(pred,columns=['Predict'])\n",
        "c1['actual']=fashion_test_y.transpose()\n",
        "res=class_acc(c1)\n",
        "print(\"Accuracy of the Logistic Regression for class 0:\"+str(res[0])+\"%\")\n",
        "print(\"Accuracy of the Logistic Regression for class 1:\"+str(res[1])+\"%\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the Logistic Regression:91.95%\n",
            "Accuracy of the Logistic Regression for class 0:92.7%\n",
            "Accuracy of the Logistic Regression for class 1:91.2%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}